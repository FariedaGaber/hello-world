{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_display(data):\n",
    "    # Display the DataFrame with scroll\n",
    "    # Define the height and width for the scrollable area\n",
    "    display(HTML(f'''\n",
    "    <div style=\"height: 500px; overflow-y: scroll; overflow-x: scroll; border: 1px solid black; padding: 5px;\">\n",
    "        {data.to_html(max_rows=None, max_cols=None)}\n",
    "    </div>\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triage = pd.read_csv(\"/data/local/llm-evaluation/mimic-iv-ed-2.2/ed/triage.csv\", on_bad_lines='skip', low_memory=False)\n",
    "vitalsigns = pd.read_csv(\"/data/local/llm-evaluation/mimic-iv-ed-2.2/ed/vitalsign.csv\", on_bad_lines='skip', low_memory=False)\n",
    "ed_stays = pd.read_csv(\"/data/local/llm-evaluation/mimic-iv-ed-2.2/ed/edstays.csv\")\n",
    "patients = pd.read_csv(\"/data/local/llm-evaluation/mimic-iv/mimic-iv-3.0/hosp/patients.csv.gz\", compression='gzip', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('/data/local/llm-evaluation/mimic-iv-note/discharge.csv').read()\n",
    "txt = txt.replace('|', ',<vl>')\n",
    "txt = txt.replace(',\"\"\"\"\\n', ',<br>')\n",
    "\n",
    "txt = txt.replace('Followup Instructions:\\n___\\n\"\"\"\"','Followup Instructions:\\n___\\n</br>|')\n",
    "#now in text only between <br> and </br> we have to replace ',' with <comma>\n",
    "import re\n",
    "txt = re.sub(r'<br>([^<]*)</br>', lambda x: x.group(0).replace(',', '<comma>'), txt)\n",
    "\n",
    "txt = txt.replace('\"', '')\n",
    "txt = txt.replace('text\\n', 'text|')\n",
    "\n",
    "# Use pandas to read the modified txt content as a CSV\n",
    "df = pd.read_csv(StringIO(txt), lineterminator='|', on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diagnosis notes and ed_stays are merged to get stay_ids values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use values in hadm_id column of df to find value of column stay_id in eds_stays and creata a new dataframe with text and stay_id\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        hadm_id = float(row['hadm_id'])\n",
    "        stay_id = ed_stays[ed_stays['hadm_id'] == hadm_id]['stay_id']\n",
    "        if stay_id.empty:\n",
    "            continue\n",
    "        df.at[index, 'stay_id'] = stay_id.iloc[0]\n",
    "    except Exception as e:\n",
    "        print(f\"{e} at {index}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe where stay_id is not NaN\n",
    "df = df[df['stay_id'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine traige and diagnosis notes usig stayids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now merge triage and df on stay_id\n",
    "df_merged = pd.merge(triage, df, on=\"stay_id\", how=\"inner\")\n",
    "df = df_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge with ed_stays on stay_id to get gender and race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_age = pd.merge(df, ed_stays, on='stay_id')\n",
    "df = df_merged_age.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get unique on the subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique rows from merged_df based on subject_id_x\n",
    "unique_df = df.drop_duplicates(subset=['subject_id_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting tests from the text and store in new column named tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests(text):\n",
    "    lower_text = text.lower()\n",
    "    try:\n",
    "        if \"discharge labs\" in lower_text.split(\"pertinent results:\")[1].split('brief hospital course:')[0]:\n",
    "            return lower_text.split(\"pertinent results:\")[1].split('brief hospital course:')[0].split('discharge labs')[0]\n",
    "        else:\n",
    "            return lower_text.split(\"pertinent results:\")[1].split('brief hospital course:')[0]\n",
    "    except:\n",
    "        print(lower_text)\n",
    "        return None\n",
    "\n",
    "unique_df[\"tests\"] = unique_df['text'].apply(get_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get age from patient dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge unique_df with patient on subject_id and drop duplicate columns\n",
    "unique_df = pd.merge(unique_df, patients, on='subject_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get medication from the text volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medication(text):\n",
    "    lower_text = text.lower()\n",
    "    try:\n",
    "        return lower_text.split(\"medications on admission:\")[1].split('discharge medications:')[0]\n",
    "    except:\n",
    "        # print(lower_text)\n",
    "        return None\n",
    "\n",
    "unique_df[\"past-medication\"] = unique_df['text'].apply(get_medication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the \"final.csv\"\n",
    "df = pd.read_csv('/data/local/llm-evaluation/processed/second_opinion/final.csv')\n",
    "\n",
    "## load diagnosis.csv which has the icd-code for each patient \n",
    "diagnostics = pd.read_csv('/data/local/llm-evaluation/mimic-iv-ed-2.2/ed/diagnosis.csv',on_bad_lines='skip')\n",
    "## only the data where \"seq_num\" equals 1. \"seq_num\" provides a pseudo-order for the ICD codes, with a value of 1 usually indicating highest relevance and a value of 9 indicating least relevance.\n",
    "diagnostics = diagnostics[diagnostics[\"seq_num\"] == 1]\n",
    "\n",
    "## merge diagnostics in df to include icd_code and icd_title in df\n",
    "df = df.merge(diagnostics[['stay_id', 'icd_code', 'icd_title', \"icd_version\"]],\n",
    "              on='stay_id', how='left')\n",
    "\n",
    "## delete the icd_code = NaN\n",
    "df = df.dropna(subset=['icd_code'])\n",
    "\n",
    "## drop columns that are not needed\n",
    "df = df.drop(columns=[\"note_id\", \"note_type\", \"note_seq\", \"charttime\", \"storetime\", \"intime\", \"outtime\", \"arrival_transport\", \"disposition\", \"anchor_year\", \"anchor_year_group\", \"dod\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge temperature, heartrate, resprate, o2sat, sbp, dbp\n",
    "def create_vitals(row):\n",
    "    vitals = []\n",
    "    \n",
    "    # Check if each value is not NaN, and append the corresponding string\n",
    "    if not pd.isna(row['temperature']):\n",
    "        vitals.append(f\"Temperature: {row['temperature']}\")\n",
    "    if not pd.isna(row['heartrate']):\n",
    "        vitals.append(f\"Heartrate: {row['heartrate']}\")\n",
    "    if not pd.isna(row['resprate']):\n",
    "        vitals.append(f\"resprate: {row['resprate']}\")\n",
    "    if not pd.isna(row['o2sat']):\n",
    "        vitals.append(f\"o2sat: {row['o2sat']}\")\n",
    "    if not pd.isna(row['sbp']):\n",
    "        vitals.append(f\"sbp: {row['sbp']}\")   \n",
    "    if not pd.isna(row['dbp']):\n",
    "        vitals.append(f\"dbp: {row['dbp']}\") \n",
    "    \n",
    "    # Join the parts with a comma and space\n",
    "    return \", \".join(vitals)\n",
    "\n",
    "df.loc[:,'initial_vitals'] = df.apply(create_vitals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge Gender, Race, Year\n",
    "def create_patient_info(row):\n",
    "    patient_info = []\n",
    "    \n",
    "    # Check if each value is not NaN, and append the corresponding string\n",
    "    if row[\"gender\"] == \"F\":\n",
    "        patient_info.append(\"Gender: Female\")\n",
    "    elif row[\"gender\"] == \"M\":\n",
    "        patient_info.append(\"Gender: Male\")\n",
    "    else:\n",
    "        patient_info.append(f\"Gender: {row['gender']}\")\n",
    "\n",
    "    patient_info.append(f\"Race: {row['race']}\")\n",
    "    patient_info.append(f\"Age: {row['anchor_age']}\")\n",
    "    \n",
    "    # Join the parts with a comma and space\n",
    "    return \", \".join(patient_info)\n",
    "\n",
    "df.loc[:,'patient_info'] = df.apply(create_patient_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop columns that are not needed\n",
    "df = df.drop(columns=[\"gender\", \"race\", \"anchor_age\", \"temperature\", \"heartrate\", \"resprate\", \"o2sat\", \"sbp\", \"dbp\"])\n",
    "\n",
    "## rearrange the columns of the dataframe\n",
    "df = df[['stay_id', 'subject_id', 'hadm_id', \"text\", 'patient_info', 'initial_vitals', 'pain', 'chiefcomplaint', 'preprocessed_text', 'past-medication', 'tests', 'acuity', 'icd_code', 'icd_title', 'icd_version']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove rows that have nans in acuity, because acuity will be predicted and nans dont carry information\n",
    "df = df.dropna(subset=['acuity'])\n",
    "df = df.dropna(subset=['tests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert nans to empty strings\n",
    "df[\"pain\"] = df['pain'].fillna(\"\")\n",
    "df[\"chiefcomplaint\"] = df['chiefcomplaint'].fillna(\"\")\n",
    "df[\"past-medication\"] = df['past-medication'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert numpy.float64 to numpy.int64\n",
    "df['acuity'] = df['acuity'].astype(np.int64)\n",
    "df['hadm_id'] = df['hadm_id'].astype(np.int64)\n",
    "df['icd_version'] = df['icd_version'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the rows that have \"history of present illness\" in the \"text\" column and keep only these rows\n",
    "hpi = df['text'].str.contains('history of present illness', case=False, na=False)\n",
    "hpi_index = hpi[hpi==True].index\n",
    "df = df.loc[hpi_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract HPI from the raw text\n",
    "def extract_hpi(text):\n",
    "    pos_past_med_hist = text.lower().find('past medical history:')\n",
    "    pos_soc_hist = text.lower().find('social history:')\n",
    "    pos_fam_hist = text.lower().find('family history:')\n",
    "    #text = text.replace(\"\\n\", \" \")\n",
    "    if pos_past_med_hist != -1:\n",
    "        return text[:pos_past_med_hist].strip()\n",
    "    elif pos_soc_hist != -1:\n",
    "        return text[:pos_soc_hist].strip()\n",
    "    elif pos_soc_hist != -1:\n",
    "        return text[:pos_fam_hist].strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df[\"HPI\"] = df[\"preprocessed_text\"].apply(extract_hpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract diagnosis from the raw text\n",
    "def extract_diagnosis(text):\n",
    "    split_text = text.split(\"Discharge Diagnosis:\" )[-1].split(\"Discharge Condition:\")[0]\n",
    "    #split_text = split_text.replace(\"\\n\", \" \")\n",
    "    split_text= split_text.replace('<comma>', ', ')\n",
    "    return(\"Discharge Diagnosis: \" + split_text)\n",
    "\n",
    "df[\"diagnosis\"] = df[\"text\"].apply(extract_diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut length HPI >2000 and test >3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_lengths = df['HPI'].str.len()\n",
    "mask = string_lengths<2000\n",
    "df = df[mask]\n",
    "\n",
    "string_lengths = df['HPI'].str.len()\n",
    "mask = string_lengths>50\n",
    "df = df[mask]\n",
    "\n",
    "string_lengths = df['tests'].str.len()\n",
    "mask = string_lengths<3000\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df['tests'].str.len()\n",
    "\n",
    "#Convert the list into a pandas Series\n",
    "lengths_series = pd.Series(lengths)\n",
    "\n",
    "# Set a cap at the 95th percentile (you can adjust this)\n",
    "cap_value = lengths_series.quantile(1)\n",
    "cap_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process HPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete nans in HPI\n",
    "df = df.dropna(subset=['HPI'])\n",
    "df = df[df['HPI'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HPI preprocess\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "def extract_only_hpi(text):\n",
    "\n",
    "    ## remove everything after\n",
    "    #text = re.sub(re.compile(\"in the ED.*\", re.IGNORECASE), \"\", text)\n",
    "    text = re.sub(re.compile(r\"in the ED, initial vital.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"in the ED initial vital.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"\\bED Course.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"\\bIn ED initial VS.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"in the ED, initial VS.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"\\binitial VS.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    text = re.sub(re.compile(r\"in the ED.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"HPI\"] = df[\"HPI\"].progress_apply(extract_only_hpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the ones that have ED in them\n",
    "mask = df[\"HPI\"].str.contains(r'\\bED', case=False, na=False)\n",
    "df = df[~mask]\n",
    "## remove where test is nan to be able to compare between normal user and expert\n",
    "df = df.dropna(subset=['tests'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove header in diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove header \"discharge diagnosis\"\n",
    "def remove_header(text, header):\n",
    "    text = re.sub(re.compile(header, re.IGNORECASE), \"\", text)\n",
    "    return text\n",
    "## Remove Header in diagnosis \"discharge diagnosis\"\n",
    "df['diagnosis'] = df['diagnosis'].apply(lambda text: remove_header(text, \"discharge diagnosis:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete before including the string\n",
    "def delete_before_string(text):\n",
    "\n",
    "    # remove everything after\n",
    "    text = re.sub(re.compile(r\".*Facility:\\n___\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "    return text\n",
    "\n",
    "df['diagnosis'] = df['diagnosis'].apply(delete_before_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete before including the string\n",
    "def delete_before_string(text):\n",
    "\n",
    "    # remove everything after\n",
    "    text = re.sub(re.compile(r\".*___ Diagnosis:\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "\n",
    "    return text\n",
    "df['diagnosis'] = df['diagnosis'].apply(delete_before_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete after \"PMH\" which stand for past medical history\n",
    "def delete_after_string(text):\n",
    "\n",
    "    # remove everything after\n",
    "    text = re.sub(re.compile(r\"PMH.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['diagnosis'] = df['diagnosis'].apply(delete_after_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"HPI\"].str.contains(' ER ', case=False, na=False)\n",
    "df = df[~mask]\n",
    "mask = df[\"HPI\"].str.contains('Emergency room', case=False, na=False)\n",
    "df = df[~mask]\n",
    "mask = df[\"HPI\"].str.contains('Emergency department', case=False, na=False)\n",
    "df = df[~mask]\n",
    "mask = df[\"HPI\"].str.contains('impression', case=False, na=False)\n",
    "df = df[~mask]\n",
    "\n",
    "\n",
    "mask = df[\"diagnosis\"].str.contains('deceased', case=False, na=False)\n",
    "df = df[~mask]\n",
    "mask = df[\"diagnosis\"].str.contains('died', case=False, na=False)\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_hpi = df[\"diagnosis\"].str.contains('history of present illness', case=False, na=False)\n",
    "df = df[~mask_hpi]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the ones that have primary in them but not surely in the beginning \\n\n",
    "mask = df[\"diagnosis\"].str.contains('primary', case=False, na=False)\n",
    "ind = df[mask].index.tolist()\n",
    "mask2 = df['diagnosis'].str.contains(r'^\\s*\\nprimary', flags=re.IGNORECASE, regex=True)\n",
    "ind2 = df[mask2].index.tolist()\n",
    "ind_drop = set(ind) - set(ind2)\n",
    "df = df[~df.index.isin(ind_drop)]\n",
    "\n",
    "## remove the ones that have secondary in them but not surely in the beginning of secondary\n",
    "mask = df[\"diagnosis\"].str.contains('secondary', case=False, na=False)\n",
    "ind = df[mask].index.tolist()\n",
    "mask2 = df['diagnosis'].str.contains('\\nsecondary', flags=re.IGNORECASE, regex=True)\n",
    "ind2 = df[mask2].index.tolist()\n",
    "ind_drop = set(ind) - set(ind2)\n",
    "df = df[~df.index.isin(ind_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"primary_diagnosis\"] = None\n",
    "df[\"secondary_diagnosis\"] = None\n",
    "## divide discharge diagnosis into primary and secondary diangosis if possible\n",
    "for i in df.index:\n",
    "    index = df[\"diagnosis\"][i].lower().find('secondary')\n",
    "    if index != -1:\n",
    "        df.loc[i, \"primary_diagnosis\"] = df[\"diagnosis\"][i][:index]\n",
    "        df.loc[i, \"secondary_diagnosis\"] = df[\"diagnosis\"][i][index:]\n",
    "    else:\n",
    "        df.loc[i, \"primary_diagnosis\"] = df[\"diagnosis\"][i]\n",
    "        df.loc[i, \"secondary_diagnosis\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete after \"___ Condition:\" which stand for past medical history\n",
    "def delete_after_string(text):\n",
    "\n",
    "    # remove everything after\n",
    "    text = re.sub(re.compile(r\"___ Condition:.*\", re.IGNORECASE | re.DOTALL), \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['primary_diagnosis'] = df['primary_diagnosis'].apply(delete_after_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete if primary_diagnosis has more than 15 single \\n (\\n are between the different diagnosis, therefore if you have more than 15 you have too many diagnosis) \n",
    "def count_single_newlines(text):\n",
    "    single_newlines = re.findall(r'(?<!\\n)\\n(?!\\n)', text)\n",
    "    return len(single_newlines)\n",
    "\n",
    "# Apply the function to the entire column and get a list of counts\n",
    "newline_counts = df['primary_diagnosis'].apply(count_single_newlines).tolist()\n",
    "\n",
    "mask = [value < 16 for value in newline_counts]\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['text', 'preprocessed_text', 'past-medication'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace colon without \\n to colon with \\n\n",
    "def colon_replacement(text):\n",
    "\n",
    "    # remove everything after\n",
    "    text = re.sub(r\":\\s*(?!\\n)\", ':\\n', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['primary_diagnosis'] = df['primary_diagnosis'].apply(colon_replacement)\n",
    "df['secondary_diagnosis'] = df['secondary_diagnosis'].apply(colon_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make diagnosis into a list for each row\n",
    "liste = df['primary_diagnosis'].apply(lambda x: [s for s in x.split('\\n') if s.strip()] if pd.notna(x) else x)\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"primary diagnoses\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"primary diagnosis\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"primary\" not in item.lower()]) \n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"====\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"\" != item.lower()])\n",
    "\n",
    "import re\n",
    "def remove_number_prefix(item):\n",
    "    return re.sub(r'^[1-8]\\)\\s*', '', item)\n",
    "liste = liste.apply(lambda lst: [remove_number_prefix(item) for item in lst])\n",
    "\n",
    "df[\"primary_diagnosis\"] = liste\n",
    "\n",
    "\n",
    "df['secondary_diagnosis'] = df['secondary_diagnosis'].fillna(\"\")\n",
    "liste = df['secondary_diagnosis'].apply(lambda x: [s for s in x.split('\\n') if s.strip()])\n",
    "\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"secondary diagnoses\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"secondary diagnosis\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"secondary\" not in item.lower()]) \n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"====\" not in item.lower()])\n",
    "liste = liste.apply(lambda lst: [item for item in lst if \"\" != item.lower()])\n",
    "\n",
    "import re\n",
    "def remove_number_prefix(item):\n",
    "    return re.sub(r'^[1-8]\\)\\s*', '', item)\n",
    "liste = liste.apply(lambda lst: [remove_number_prefix(item) for item in lst])\n",
    "\n",
    "df[\"secondary_diagnosis\"] = liste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envphd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
